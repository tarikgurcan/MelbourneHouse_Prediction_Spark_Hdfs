{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f2eb062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/tarik/spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc3836bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51486b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('lrex').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "becd6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7223078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40491321",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(path=\"hdfs://localhost:9000/Melbourne_housing_FULL.csv\",inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e92e8c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-----+----+-------+------+-------+---------+--------+--------+--------+--------+----+--------+------------+---------+------------------+---------+----------+--------------------+-------------+\n",
      "|    Suburb|            Address|Rooms|Type|  Price|Method|SellerG|     Date|Distance|Postcode|Bedroom2|Bathroom| Car|Landsize|BuildingArea|YearBuilt|       CouncilArea|Lattitude|Longtitude|          Regionname|Propertycount|\n",
      "+----------+-------------------+-----+----+-------+------+-------+---------+--------+--------+--------+--------+----+--------+------------+---------+------------------+---------+----------+--------------------+-------------+\n",
      "|Abbotsford|      68 Studley St|    2|   h|   null|    SS| Jellis|3/09/2016|     2.5|    3067|       2|       1|   1|     126|        null|     null|Yarra City Council| -37.8014|  144.9958|Northern Metropol...|         4019|\n",
      "|Abbotsford|       85 Turner St|    2|   h|1480000|     S| Biggin|3/12/2016|     2.5|    3067|       2|       1|   1|     202|        null|     null|Yarra City Council| -37.7996|  144.9984|Northern Metropol...|         4019|\n",
      "|Abbotsford|    25 Bloomburg St|    2|   h|1035000|     S| Biggin|4/02/2016|     2.5|    3067|       2|       1|   0|     156|        79.0|     1900|Yarra City Council| -37.8079|  144.9934|Northern Metropol...|         4019|\n",
      "|Abbotsford| 18/659 Victoria St|    3|   u|   null|    VB| Rounds|4/02/2016|     2.5|    3067|       3|       2|   1|       0|        null|     null|Yarra City Council| -37.8114|  145.0116|Northern Metropol...|         4019|\n",
      "|Abbotsford|       5 Charles St|    3|   h|1465000|    SP| Biggin|4/03/2017|     2.5|    3067|       3|       2|   0|     134|       150.0|     1900|Yarra City Council| -37.8093|  144.9944|Northern Metropol...|         4019|\n",
      "|Abbotsford|   40 Federation La|    3|   h| 850000|    PI| Biggin|4/03/2017|     2.5|    3067|       3|       2|   1|      94|        null|     null|Yarra City Council| -37.7969|  144.9969|Northern Metropol...|         4019|\n",
      "|Abbotsford|        55a Park St|    4|   h|1600000|    VB| Nelson|4/06/2016|     2.5|    3067|       3|       1|   2|     120|       142.0|     2014|Yarra City Council| -37.8072|  144.9941|Northern Metropol...|         4019|\n",
      "|Abbotsford|       16 Maugie St|    4|   h|   null|    SN| Nelson|6/08/2016|     2.5|    3067|       3|       2|   2|     400|       220.0|     2006|Yarra City Council| -37.7965|  144.9965|Northern Metropol...|         4019|\n",
      "|Abbotsford|       53 Turner St|    2|   h|   null|     S| Biggin|6/08/2016|     2.5|    3067|       4|       1|   2|     201|        null|     1900|Yarra City Council| -37.7995|  144.9974|Northern Metropol...|         4019|\n",
      "|Abbotsford|       99 Turner St|    2|   h|   null|     S|Collins|6/08/2016|     2.5|    3067|       3|       2|   1|     202|        null|     1900|Yarra City Council| -37.7996|  144.9989|Northern Metropol...|         4019|\n",
      "|Abbotsford|     129 Charles St|    2|   h| 941000|     S| Jellis|7/05/2016|     2.5|    3067|       2|       1|   0|     181|        null|     null|Yarra City Council| -37.8041|  144.9953|Northern Metropol...|         4019|\n",
      "|Abbotsford|       124 Yarra St|    3|   h|1876000|     S| Nelson|7/05/2016|     2.5|    3067|       4|       2|   0|     245|       210.0|     1910|Yarra City Council| -37.8024|  144.9993|Northern Metropol...|         4019|\n",
      "|Abbotsford|121/56 Nicholson St|    2|   u|   null|    PI| Biggin|7/11/2016|     2.5|    3067|       2|       2|   1|    4292|        82.0|     2009|Yarra City Council| -37.8078|  144.9965|Northern Metropol...|         4019|\n",
      "|Abbotsford|      17 Raphael St|    4|   h|   null|     W| Biggin|7/11/2016|     2.5|    3067|       6|       2|   0|     230|       147.0|     1860|Yarra City Council| -37.8066|  144.9936|Northern Metropol...|         4019|\n",
      "|Abbotsford|      98 Charles St|    2|   h|1636000|     S| Nelson|8/10/2016|     2.5|    3067|       2|       1|   2|     256|       107.0|     1890|Yarra City Council|  -37.806|  144.9954|Northern Metropol...|         4019|\n",
      "|Abbotsford|   217 Langridge St|    3|   h|1000000|     S| Jellis|8/10/2016|     2.5|    3067|    null|    null|null|    null|        null|     null|Yarra City Council|     null|      null|Northern Metropol...|         4019|\n",
      "|Abbotsford|    18a Mollison St|    2|   t| 745000|     S| Jellis|8/10/2016|     2.5|    3067|    null|    null|null|    null|        null|     null|Yarra City Council|     null|      null|Northern Metropol...|         4019|\n",
      "|Abbotsford| 6/241 Nicholson St|    1|   u| 300000|     S| Biggin|8/10/2016|     2.5|    3067|       1|       1|   1|       0|        null|     null|Yarra City Council| -37.8008|  144.9973|Northern Metropol...|         4019|\n",
      "|Abbotsford|      10 Valiant St|    2|   h|1097000|     S| Biggin|8/10/2016|     2.5|    3067|       3|       1|   2|     220|        75.0|     1900|Yarra City Council|  -37.801|  144.9989|Northern Metropol...|         4019|\n",
      "|Abbotsford|403/609 Victoria St|    2|   u| 542000|     S| Dingle|8/10/2016|     2.5|    3067|    null|    null|null|    null|        null|     null|Yarra City Council|     null|      null|Northern Metropol...|         4019|\n",
      "+----------+-------------------+-----+----+-------+------+-------+---------+--------+--------+--------+--------+----+--------+------------+---------+------------------+---------+----------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13660133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----+----+-----+------+-------+----+--------+--------+--------+--------+----+--------+------------+---------+-----------+---------+----------+----------+-------------+\n",
      "|Suburb|Address|Rooms|Type|Price|Method|SellerG|Date|Distance|Postcode|Bedroom2|Bathroom| Car|Landsize|BuildingArea|YearBuilt|CouncilArea|Lattitude|Longtitude|Regionname|Propertycount|\n",
      "+------+-------+-----+----+-----+------+-------+----+--------+--------+--------+--------+----+--------+------------+---------+-----------+---------+----------+----------+-------------+\n",
      "|     0|      0|    0|   0| 7610|     0|      0|   0|       0|       0|    8217|    8226|8728|   11810|       21115|    19306|          0|     7976|      7976|         0|            0|\n",
      "+------+-------+-----+----+-----+------+-------+----+--------+--------+--------+--------+----+--------+------------+---------+-----------+---------+----------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "982bdd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------------+------------------+-----+-----------------+------+-----------+---------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+--------------------+-------------------+-------------------+----------------+------------------+\n",
      "|summary|    Suburb|         Address|             Rooms| Type|            Price|Method|    SellerG|     Date|          Distance|          Postcode|          Bedroom2|          Bathroom|               Car|          Landsize|      BuildingArea|         YearBuilt|         CouncilArea|          Lattitude|         Longtitude|      Regionname|     Propertycount|\n",
      "+-------+----------+----------------+------------------+-----+-----------------+------+-----------+---------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+--------------------+-------------------+-------------------+----------------+------------------+\n",
      "|  count|     34857|           34857|             34857|34857|            27247| 34857|      34857|    34857|             34857|             34857|             26640|             26631|             26129|             23047|             13742|             15551|               34857|              26881|              26881|           34857|             34857|\n",
      "|   mean|      null|            null|3.0310124221820582| null|1050173.344955408|  null|       null|     null|11.184929423916007| 3116.062858618315|3.0846471471471473| 1.624798167549097|1.7288453442535114|  593.598993361392| 160.2564003565711| 1965.289884894862|                null|-37.810634295599094| 145.00185113165438|            null|7572.8883055029555|\n",
      "| stddev|      null|            null|0.9699329348975204| null|641467.1301045999|  null|       null|     null| 6.788892455935938|109.02390274290613|0.9806897285461588|0.7242120114699068|1.0107707853554244|3398.8419464599056|401.26706008485496|37.328178023136616|                null| 0.0902789045092229|0.12016876915353476|            null|4428.0903132746425|\n",
      "|    min|Abbotsford|1 Abercrombie St|                 1|    h|            85000|    PI|    @Realty|1/07/2017|              #N/A|              #N/A|                 0|                 0|                 0|                 0|               0.0|              1196|                #N/A|          -38.19043|          144.42379|            #N/A|              #N/A|\n",
      "|    max|  viewbank|   9b Stewart St|                16|    u|         11200000|     W|voglwalpole|9/12/2017|               9.9|              3978|                30|                12|                26|            433014|           44515.0|              2106|Yarra Ranges Shir...|           -37.3902|          145.52635|Western Victoria|               984|\n",
      "+-------+----------+----------------+------------------+-----+-----------------+------+-----------+---------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+--------------------+-------------------+-------------------+----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "346709f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of original data rows:  34857\n",
      "number of data rows after deleting duplicated data:  34856\n",
      "number of duplicated data:  1\n"
     ]
    }
   ],
   "source": [
    "#count the number of original data rows\n",
    "n1 = df.count()\n",
    "print(\"number of original data rows: \", n1)\n",
    "#count the number of data rows after deleting duplicated data\n",
    "n2 = df.dropDuplicates().count()\n",
    "print(\"number of data rows after deleting duplicated data: \", n2)\n",
    "n3 = n1 - n2\n",
    "print(\"number of duplicated data: \", n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea8cdd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of missing value rows:  25970\n"
     ]
    }
   ],
   "source": [
    "dfNoMissingValue = df.dropDuplicates().dropna(\n",
    "    how=\"any\")# use how=\"all\" for all column missing data\n",
    "numberOfMissingValueAny = n1 - dfNoMissingValue.count()\n",
    "print(\"number of missing value rows: \", numberOfMissingValueAny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "224bd1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Suburb: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- Rooms: integer (nullable = true)\n",
      " |-- Type: string (nullable = true)\n",
      " |-- Price: integer (nullable = true)\n",
      " |-- Method: string (nullable = true)\n",
      " |-- SellerG: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Distance: string (nullable = true)\n",
      " |-- Postcode: string (nullable = true)\n",
      " |-- Bedroom2: integer (nullable = true)\n",
      " |-- Bathroom: integer (nullable = true)\n",
      " |-- Car: integer (nullable = true)\n",
      " |-- Landsize: integer (nullable = true)\n",
      " |-- BuildingArea: double (nullable = true)\n",
      " |-- YearBuilt: integer (nullable = true)\n",
      " |-- CouncilArea: string (nullable = true)\n",
      " |-- Lattitude: double (nullable = true)\n",
      " |-- Longtitude: double (nullable = true)\n",
      " |-- Regionname: string (nullable = true)\n",
      " |-- Propertycount: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c024a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f\n",
    "df = df.withColumn('year', f.substring('Date', -4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef66f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "df = df.withColumn(\"Rooms\", df[\"Rooms\"].cast(FloatType())) \\\n",
    "   .withColumn(\"Bedroom2\", df[\"Bedroom2\"].cast(FloatType())) \\\n",
    "   .withColumn(\"Bathroom\",df[\"Bathroom\"].cast(FloatType())) \\\n",
    "   .withColumn(\"Car\", df[\"Car\"].cast(FloatType())) \\\n",
    "   .withColumn(\"Landsize\", df[\"Landsize\"].cast(FloatType())) \\\n",
    "   .withColumn(\"BuildingArea\", df[\"BuildingArea\"].cast(FloatType())) \\\n",
    "   .withColumn(\"YearBuilt\", df[\"YearBuilt\"].cast(FloatType())) \\\n",
    "   .withColumn(\"Lattitude\", df[\"Lattitude\"].cast(FloatType())) \\\n",
    "   .withColumn(\"Longtitude\", df[\"Longtitude\"].cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0522dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Suburb: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- Rooms: float (nullable = true)\n",
      " |-- Type: string (nullable = true)\n",
      " |-- Price: integer (nullable = true)\n",
      " |-- Method: string (nullable = true)\n",
      " |-- SellerG: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Distance: string (nullable = true)\n",
      " |-- Postcode: string (nullable = true)\n",
      " |-- Bedroom2: float (nullable = true)\n",
      " |-- Bathroom: float (nullable = true)\n",
      " |-- Car: float (nullable = true)\n",
      " |-- Landsize: float (nullable = true)\n",
      " |-- BuildingArea: float (nullable = true)\n",
      " |-- YearBuilt: float (nullable = true)\n",
      " |-- CouncilArea: string (nullable = true)\n",
      " |-- Lattitude: float (nullable = true)\n",
      " |-- Longtitude: float (nullable = true)\n",
      " |-- Regionname: string (nullable = true)\n",
      " |-- Propertycount: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3653da66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean Price:  1050173.344955408\n",
      "mean Rooms:  3.0310124221820582\n",
      "mean Bedroom2:  3.0846471471471473\n",
      "mean Bathroom:  1.624798167549097\n",
      "mean Car:  1.7288453442535114\n",
      "mean Landsize:  593.598993361392\n",
      "mean BuildingArea:  160.2564003607925\n",
      "mean YearBuilt:  1965.289884894862\n"
     ]
    }
   ],
   "source": [
    "meanPrice = df.groupBy().avg(\"Price\").take(1)[0][0]\n",
    "print(\"mean Price: \", meanPrice)\n",
    "meanRooms = df.groupBy().avg(\"Rooms\").take(1)[0][0]\n",
    "print(\"mean Rooms: \", meanRooms)\n",
    "MeanBedroom2 = df.groupBy().avg(\"Bedroom2\").take(1)[0][0]\n",
    "print(\"mean Bedroom2: \", MeanBedroom2)\n",
    "MeanBathroom = df.groupBy().avg(\"Bathroom\").take(1)[0][0]\n",
    "print(\"mean Bathroom: \", MeanBathroom)\n",
    "MeanCar = df.groupBy().avg(\"Car\").take(1)[0][0]\n",
    "print(\"mean Car: \", MeanCar)\n",
    "MeanLandsize = df.groupBy().avg(\"Landsize\").take(1)[0][0]\n",
    "print(\"mean Landsize: \", MeanLandsize)\n",
    "MeanBuildingArea = df.groupBy().avg(\"BuildingArea\").take(1)[0][0]\n",
    "print(\"mean BuildingArea: \", MeanBuildingArea)\n",
    "MeanYearBuilt = df.groupBy().avg(\"YearBuilt\").take(1)[0][0]\n",
    "print(\"mean YearBuilt: \", MeanYearBuilt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e53902e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       avg(Price)|\n",
      "+-----------------+\n",
      "|1050173.344955408|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=df.fillna(\n",
    "    {\n",
    "        'Car': MeanCar,\n",
    "        'Rooms': meanRooms, 'Landsize': MeanLandsize,\n",
    "        'Bedroom2': MeanBedroom2, 'BuildingArea': MeanBuildingArea,\n",
    "        'Bathroom': MeanBathroom, 'YearBuilt': MeanYearBuilt\n",
    "    })\n",
    "#just for experiment\n",
    "df.groupBy().avg(\"Price\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cb1c1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|            Price|\n",
      "+-------+-----------------+\n",
      "|  count|            27247|\n",
      "|   mean|1050173.344955408|\n",
      "| stddev|641467.1301045999|\n",
      "|    min|            85000|\n",
      "|    max|         11200000|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Price').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db5616c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df['Price'] < 300000).select('Price').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45cc2fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(df['Price'] > 300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4536bbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df['Price'] > 4000000).select('Price').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5162b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(df['Price'] < 4000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b21c1c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|             Rooms|\n",
      "+-------+------------------+\n",
      "|  count|             26861|\n",
      "|   mean| 2.999776627824727|\n",
      "| stddev|0.9331329517945214|\n",
      "|    min|               1.0|\n",
      "|    max|              12.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Rooms').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d68ad4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Rooms|\n",
      "+-----+\n",
      "| 10.0|\n",
      "|  9.0|\n",
      "| 10.0|\n",
      "| 10.0|\n",
      "| 10.0|\n",
      "| 10.0|\n",
      "| 12.0|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['Rooms'] > 8).select('Rooms').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58099d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(df['Rooms'] < 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8c39808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "Suburb_indexer=StringIndexer(inputCol=\"Suburb\",outputCol=\"SuburbIndex\")\n",
    "df=Suburb_indexer.fit(df).transform(df)\n",
    "\n",
    "Postcode_indexer=StringIndexer(inputCol=\"Postcode\",outputCol=\"PostcodeIndex\")\n",
    "df=Postcode_indexer.fit(df).transform(df)\n",
    "\n",
    "Regionname_indexer=StringIndexer(inputCol=\"Regionname\",outputCol=\"RegionnameIndex\")\n",
    "df=Regionname_indexer.fit(df).transform(df)\n",
    "\n",
    "Distance_indexer=StringIndexer(inputCol=\"Distance\",outputCol=\"DistanceIndex\")\n",
    "df=Distance_indexer.fit(df).transform(df)\n",
    "\n",
    "CouncilArea_indexer=StringIndexer(inputCol=\"CouncilArea\",outputCol=\"CouncilAreaIndex\")\n",
    "df=CouncilArea_indexer.fit(df).transform(df)\n",
    "\n",
    "Propertycount_indexer=StringIndexer(inputCol=\"Propertycount\",outputCol=\"PropertycountIndex\")\n",
    "df=Propertycount_indexer.fit(df).transform(df)\n",
    "\n",
    "Year_indexer=StringIndexer(inputCol=\"year\",outputCol=\"YearIndex\")\n",
    "df=Year_indexer.fit(df).transform(df)\n",
    "\n",
    "Type_indexer=StringIndexer(inputCol=\"Type\",outputCol=\"TypeIndex\")\n",
    "df=Type_indexer.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "112b1bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Suburb: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- Rooms: float (nullable = false)\n",
      " |-- Type: string (nullable = true)\n",
      " |-- Price: integer (nullable = true)\n",
      " |-- Method: string (nullable = true)\n",
      " |-- SellerG: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Distance: string (nullable = true)\n",
      " |-- Postcode: string (nullable = true)\n",
      " |-- Bedroom2: float (nullable = false)\n",
      " |-- Bathroom: float (nullable = false)\n",
      " |-- Car: float (nullable = false)\n",
      " |-- Landsize: float (nullable = false)\n",
      " |-- BuildingArea: float (nullable = false)\n",
      " |-- YearBuilt: float (nullable = false)\n",
      " |-- CouncilArea: string (nullable = true)\n",
      " |-- Lattitude: float (nullable = true)\n",
      " |-- Longtitude: float (nullable = true)\n",
      " |-- Regionname: string (nullable = true)\n",
      " |-- Propertycount: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- SuburbIndex: double (nullable = false)\n",
      " |-- PostcodeIndex: double (nullable = false)\n",
      " |-- RegionnameIndex: double (nullable = false)\n",
      " |-- DistanceIndex: double (nullable = false)\n",
      " |-- CouncilAreaIndex: double (nullable = false)\n",
      " |-- PropertycountIndex: double (nullable = false)\n",
      " |-- YearIndex: double (nullable = false)\n",
      " |-- TypeIndex: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63ef4e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|         Landsize|\n",
      "+-------+-----------------+\n",
      "|  count|            26840|\n",
      "|   mean|593.8671487367633|\n",
      "| stddev| 3074.28424873174|\n",
      "|    min|              0.0|\n",
      "|    max|         433014.0|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Landsize').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7da2b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('Price').count()\n",
    "df = df.na.drop(subset = \"Price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "633183b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|            features|  Price|\n",
      "+--------------------+-------+\n",
      "|[-37.799598693847...|1480000|\n",
      "|[-37.807899475097...|1035000|\n",
      "|[-37.809299468994...|1465000|\n",
      "+--------------------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vectorAssembler = VectorAssembler(inputCols = ['Lattitude', 'Longtitude', 'SuburbIndex', 'RegionnameIndex', 'CouncilAreaIndex', 'TypeIndex', 'DistanceIndex', 'PostcodeIndex', 'Rooms', 'Bedroom2', 'Bathroom', 'Car', 'Landsize', 'BuildingArea', 'YearBuilt'], outputCol = 'features',handleInvalid='skip')\n",
    "vhouse_df = vectorAssembler.transform(df)\n",
    "vhouse_df = vhouse_df.select(['features', 'Price'])\n",
    "vhouse_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd7d418f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|            features|    Price|\n",
      "+--------------------+---------+\n",
      "|[-37.799598693847...|1480000.0|\n",
      "|[-37.807899475097...|1035000.0|\n",
      "|[-37.809299468994...|1465000.0|\n",
      "+--------------------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vhouse_df = vhouse_df.withColumn(\"Price\", vhouse_df[\"Price\"].cast(FloatType()))\n",
    "vhouse_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3f8bdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+\n",
      "|            features|    Price|     features_scaled|\n",
      "+--------------------+---------+--------------------+\n",
      "|[-37.799598693847...|1480000.0|[-411.06892262741...|\n",
      "|[-37.807899475097...|1035000.0|[-411.15919324729...|\n",
      "+--------------------+---------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "# Initialize the `standardScaler`\n",
    "standardScaler = StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\")\n",
    "\n",
    "# Fit the DataFrame to the scaler\n",
    "scaler = standardScaler.fit(vhouse_df)\n",
    "\n",
    "# Transform the data in `df` with the scaler\n",
    "scaled_df = scaler.transform(vhouse_df)\n",
    "\n",
    "# Inspect the result\n",
    "scaled_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3438d580",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df = scaled_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4cb46555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|            features|    Price|\n",
      "+--------------------+---------+\n",
      "|[-411.06892262741...|1480000.0|\n",
      "|[-411.15919324729...|1035000.0|\n",
      "|[-411.17441811746...|1465000.0|\n",
      "+--------------------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaled_df = scaled_df.withColumn(\"features\", scaled_df[\"features_scaled\"])\n",
    "scaled_df= scaled_df.drop('features_scaled')\n",
    "scaled_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7c8b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = scaled_df.randomSplit([0.7, 0.3])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4928acff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-127990.19041411101,68270.13797250677,-55792.89349964961,-119917.04296540517,-96738.83845678493,-97535.73970382372,1639.661817415845,24806.639553540586,97089.67032013868,53781.27030730667,149082.89967226054,13362.967854799948,39964.024606101346,144538.6005687227,-112519.62632407655]\n",
      "Intercept: -126066559.13476793\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='Price', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model = lr.fit(train_df)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3048f618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+------------------+\n",
      "|            features|   Price|        prediction|\n",
      "+--------------------+--------+------------------+\n",
      "|[-415.23348466268...|860000.0| 1350710.387042299|\n",
      "|[-415.14441709794...|670000.0|1489734.3064708859|\n",
      "|[-415.14412670532...|563000.0|1018820.5972778797|\n",
      "+--------------------+--------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predict testing data using our model\n",
    "prediction = lr_model.transform(test_df)\n",
    "#show some prediction results\n",
    "prediction.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc442076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 405800.242794\n",
      "r2: 0.509443\n"
     ]
    }
   ],
   "source": [
    "trainingSummary = lr_model.summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41483d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 357273\n",
      "R2 (R2) on test data = 0.622282\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "dt = DecisionTreeRegressor(featuresCol ='features', labelCol = 'Price')\n",
    "dt_model = dt.fit(train_df)\n",
    "dt_predictions = dt_model.transform(test_df)\n",
    "dt_evaluator = RegressionEvaluator(labelCol=\"Price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "dt_evaluator_r2 = RegressionEvaluator(labelCol=\"Price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "rmse = dt_evaluator.evaluate(dt_predictions)\n",
    "r2 = dt_evaluator_r2.evaluate(dt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "print(\"R2 (R2) on test data = %g\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "434899b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+--------------------+\n",
      "|       prediction|   Price|            features|\n",
      "+-----------------+--------+--------------------+\n",
      "|961398.1461729957|860000.0|[-415.23348466268...|\n",
      "|799920.4110186616|670000.0|[-415.14441709794...|\n",
      "| 633331.938134118|563000.0|[-415.14412670532...|\n",
      "|822124.5958361379|737500.0|[-415.12856995787...|\n",
      "|807014.8820903505|650000.0|[-415.07546959323...|\n",
      "+-----------------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "gbt = GBTRegressor(featuresCol = 'features', labelCol = 'Price', maxIter=10)\n",
    "gbt_model = gbt.fit(train_df)\n",
    "gbt_predictions = gbt_model.transform(test_df)\n",
    "gbt_predictions.select('prediction', 'Price', 'features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73f28603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 305639\n",
      "R2 Error (R2) on test data = 0.72357\n"
     ]
    }
   ],
   "source": [
    "gbt_evaluator = RegressionEvaluator(labelCol=\"Price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "gbt_evaluator_r2 = RegressionEvaluator(labelCol=\"Price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "rmse = gbt_evaluator.evaluate(gbt_predictions)\n",
    "r2 = gbt_evaluator_r2.evaluate(gbt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "print(\"R2 Error (R2) on test data = %g\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a3da15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+--------------------+\n",
      "|        prediction|    Price|            features|\n",
      "+------------------+---------+--------------------+\n",
      "|1238358.0367740605| 975000.0|[-415.18718778227...|\n",
      "|1181854.5576047963|1350000.0|[-415.15010049634...|\n",
      "|1181854.5576047963| 737500.0|[-415.12856995787...|\n",
      "|1181854.5576047963| 890000.0|[-415.11550229001...|\n",
      "|1181854.5576047963| 750000.0|[-415.10737129667...|\n",
      "+------------------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 351103\n",
      "R2 Error (R2) on test data = 0.647568\n",
      "RandomForestRegressionModel: uid=RandomForestRegressor_5fa816f7a655, numTrees=20, numFeatures=15\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(scaled_df)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = scaled_df.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestRegressor(featuresCol='indexedFeatures', labelCol='Price')\n",
    "\n",
    "# Chain indexer and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, rf])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"Price\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(labelCol=\"Price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"Price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "print(\"R2 Error (R2) on test data = %g\" % r2)\n",
    "\n",
    "rfModel = model.stages[1]\n",
    "print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c76184",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
